{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "502e1188",
   "metadata": {},
   "source": [
    "# YouTube ChatBot (RAG)\n",
    "Chat with any YouTube video using transcript + embeddings + retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nirav Rupapara\\Desktop\\YouTube-ChatBot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9d81dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint , ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94c92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "TOP_K = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64188ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(youtube_url: str) -> str:\n",
    "    pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
    "    match = re.search(pattern, youtube_url)\n",
    "    if not match:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    return match.group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3e2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_youtube_transcript(video_id: str) -> str:\n",
    "#     transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "#     return \" \".join(segment[\"text\"] for segment in transcript)\n",
    "\n",
    "def load_youtube_transcript(video_id: str) -> str:\n",
    "    api_object = YouTubeTranscriptApi()\n",
    "    transcript_list = api_object.fetch(video_id)\n",
    "    \n",
    "\n",
    "    transcript_text =\" \".join(item.text for item in transcript_list)\n",
    "\n",
    "    return transcript_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "054b3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE,\n",
    "        chunk_overlap=CHUNK_OVERLAP\n",
    "    )\n",
    "    return splitter.create_documents([text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337d64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(documents):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    texts = [doc.page_content for doc in documents]\n",
    "    return FAISS.from_texts(texts, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ac3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever(vector_store):\n",
    "    return vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": TOP_K}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa199f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    llm_endpoint = HuggingFaceEndpoint(\n",
    "        repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        temperature=0,\n",
    "        max_new_tokens=512\n",
    "    )\n",
    "\n",
    "    chat_model = ChatHuggingFace(llm=llm_endpoint)\n",
    "    return chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e9bc434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Answer Generation (LLM)\n",
    "# =========================\n",
    "\n",
    "def generate_answer(llm, question: str, retrieved_docs):\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46fb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Main Pipeline\n",
    "# =========================\n",
    "\n",
    "def run_youtube_chatbot(youtube_url: str, question: str):\n",
    "    video_id = extract_video_id(youtube_url)\n",
    "\n",
    "    transcript_text = load_youtube_transcript(video_id)\n",
    "\n",
    "    documents = split_text(transcript_text)\n",
    "\n",
    "    vector_store = create_vector_store(documents)\n",
    "\n",
    "    retriever = get_retriever(vector_store)\n",
    "\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "    model = load_llm()\n",
    "    answer = generate_answer(llm=model, question=question,retrieved_docs= retrieved_docs)\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c30362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' This video is about optimization of algorithms, specifically for finding the sum of a subarray with a minimum value and the time and space complexity analysis of different approaches. The speaker emphasizes the importance of understanding concepts and keeping them intact, and provides an analysis of the time and space complexity for various methods, including one with nested loops. The video references a previous problem in the same playlist which is related to finding the minimum from every subarray.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 554, 'total_tokens': 643}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b1c05-65f2-7c81-99d3-18124cbee0eb-0' usage_metadata={'input_tokens': 554, 'output_tokens': 89, 'total_tokens': 643}\n"
     ]
    }
   ],
   "source": [
    "youtube_url = \"https://youtu.be/gIrMptNPf5M?si=UJ0D5PUVHP5MCyYL\"\n",
    "question = \"What is this video about?\"\n",
    "\n",
    "docs = run_youtube_chatbot(youtube_url, question)\n",
    "print(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "345ab307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(docs))\n",
    "print(type(docs.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996c8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
